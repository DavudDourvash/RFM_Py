{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:10.308007Z",
     "start_time": "2025-04-03T09:08:09.814624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import locale\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, 'fa_IR.UTF-8')\n"
   ],
   "id": "4d648bfb15ae932c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fa_IR.UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:10.319443Z",
     "start_time": "2025-04-03T09:08:10.308007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def quantile_score(vec, score):\n",
    "    scorevec = np.zeros(len(vec))\n",
    "    qu = np.quantile(vec, np.linspace(0, 1, score + 1))\n",
    "    scorevec[(vec <= qu[1]) & (vec >= qu[0])] = 1\n",
    "    for i in range(1, score - 1):\n",
    "        scorevec[(vec <= qu[i + 1]) & (vec > qu[i])] = i + 1\n",
    "    scorevec[vec > qu[score]] = score\n",
    "    return scorevec\n",
    "\n"
   ],
   "id": "42e36a5360a93879",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:14.327033Z",
     "start_time": "2025-04-03T09:08:10.529416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read Data\n",
    "# Folder containing Parquet files\n",
    "folder_path = \"Data/data/*.parquet\"\n",
    "\n",
    "# List all parquet files\n",
    "parquet_files = glob.glob(folder_path)\n",
    "\n",
    "# Read and concatenate all files\n",
    "df = pd.concat([pd.read_parquet(f) for f in parquet_files], ignore_index=True)\n"
   ],
   "id": "32b61f21856d28c8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:14.338845Z",
     "start_time": "2025-04-03T09:08:14.332942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Functions\n",
    "\n",
    "def quantile_score(vec, score):\n",
    "    scorevec = np.zeros(len(vec))\n",
    "    qu = np.quantile(vec, np.linspace(0, 1, score + 1))\n",
    "    scorevec[(vec <= qu[1]) & (vec >= qu[0])] = 1\n",
    "    for i in range(1, score - 1):\n",
    "        scorevec[(vec <= qu[i + 1]) & (vec > qu[i])] = i + 1\n",
    "    scorevec[vec > qu[score]] = score\n",
    "    return scorevec\n",
    "\n",
    "def generate_dates(years, months, days30, days31):\n",
    "    dates = []\n",
    "    for month in months:\n",
    "        if month in Months:\n",
    "            dates.append(f\"{years}{month}{days31}\")\n",
    "        else:\n",
    "            dates.append(f\"{years}{month}{days30}\")\n",
    "    return dates\n"
   ],
   "id": "d8fba669f710be5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:14.370704Z",
     "start_time": "2025-04-03T09:08:14.364028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "\n",
    "start_date = 14030101  # Start train\n",
    "target_date = 14030631  # End train\n",
    "\n",
    "Years = [\"1403\"]\n",
    "Months = [\"{:02d}\".format(i) for i in range(1, 13)]  # Generates \"01\" to \"12\"\n",
    "Days30 = [\"{:02d}\".format(i) for i in range(1, 31)]  # Generates \"01\" to \"30\"\n",
    "Days31 = [\"{:02d}\".format(i) for i in range(1, 32)]  # Generates \"01\" to \"31\"\n",
    "\n",
    "print(\"Years:\", Years)\n",
    "print(\"Months:\", Months)\n",
    "print(\"Days30:\", Days30)\n",
    "print(\"Days31:\", Days31)\n"
   ],
   "id": "a561ff095a7eef73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years: ['1403']\n",
      "Months: ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
      "Days30: ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30']\n",
      "Days31: ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:14.478554Z",
     "start_time": "2025-04-03T09:08:14.471386Z"
    }
   },
   "cell_type": "code",
   "source": "main_dates = generate_dates(Years, Months, Days30, Days31)\n",
   "id": "5be82036c8186e9e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:14.516859Z",
     "start_time": "2025-04-03T09:08:14.508259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove specific dates\n",
    "excluded_dates = {14021031, 14021131, 14021231, 14030731, 14030831, 14030931, 14031031, 14031131, 14031231}\n",
    "main_dates = [date for date in main_dates if date not in excluded_dates]"
   ],
   "id": "2367f2de49ae003f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:08:14.637977Z",
     "start_time": "2025-04-03T09:08:14.521356Z"
    }
   },
   "cell_type": "code",
   "source": "DimDate = pd.read_csv(\"Data/data/DimDate.csv\")",
   "id": "651960c2a10c3c30",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:26:24.189076Z",
     "start_time": "2025-03-18T14:25:59.536664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert date column to string\n",
    "df[\"date_CHR\"] = df[\"date\"].astype(str)\n",
    "\n",
    "# Create Miladi_Num by extracting and concatenating substrings\n",
    "df[\"Miladi_Num\"] = df[\"date_CHR\"].str[:4] + df[\"date_CHR\"].str[5:7] + df[\"date_CHR\"].str[8:10]\n",
    "\n",
    "# Convert Miladi column to string\n",
    "DimDate[\"Miladi_CHR\"] = DimDate[\"Miladi\"].astype(str)\n",
    "\n",
    "# Create Miladi_Num in DimDate\n",
    "DimDate[\"Miladi_Num\"] = DimDate[\"Miladi_CHR\"].str[:4] + DimDate[\"Miladi_CHR\"].str[5:7] + DimDate[\"Miladi_CHR\"].str[8:10]\n",
    "\n",
    "# Select specific columns\n",
    "DimDateS = DimDate[[\"Jalali_1\", \"Miladi_Num\"]]\n",
    "\n",
    "# Left join on Miladi_Num\n",
    "df = df.merge(DimDateS, on=\"Miladi_Num\", how=\"left\")\n",
    "\n",
    "# Create Shamsi_Date and convert to numeric\n",
    "df[\"Shamsi_Date_Num\"] = (df[\"Jalali_1\"].str[:4] + df[\"Jalali_1\"].str[5:7] + df[\"Jalali_1\"].str[8:10]).astype(int)\n"
   ],
   "id": "ff69a4e0069bb0d9",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Jalali_1'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Jalali_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mmerge(DimDateS, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMiladi_Num\u001B[39m\u001B[38;5;124m\"\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Create Shamsi_Date and convert to numeric\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShamsi_Date_Num\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m (df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJalali_1\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstr[:\u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m+\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJalali_1\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstr[\u001B[38;5;241m5\u001B[39m:\u001B[38;5;241m7\u001B[39m] \u001B[38;5;241m+\u001B[39m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJalali_1\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstr[\u001B[38;5;241m8\u001B[39m:\u001B[38;5;241m10\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Jalali_1'"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:14:40.274665Z",
     "start_time": "2025-04-03T09:14:39.834594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming df is already a pandas DataFrame\n",
    "TrainRFM = df[df[\"module\"] == \"Giftcard\"]\n",
    "\n",
    "TrainRFM = TrainRFM[TrainRFM[\"payment_status\"] == \"payed\"]\n",
    "\n",
    "TrainRFM.columns"
   ],
   "id": "b1b3074cf79e4ef6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'user_id', 'date', 'client_type', 'status', 'payment_status',\n",
       "       'type', 'module', 'product_name', 'initial_total', 'product_price',\n",
       "       'converted_value', 'qty', 'module_unit_price', 'Amount_in_dollars',\n",
       "       'first_purchased'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:14:31.337110Z",
     "start_time": "2025-04-03T09:14:31.107124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group by user_id and calculate min and max dates\n",
    "TrainRFM_RB = TrainRFM.groupby(\"user_id\", as_index=False).agg(\n",
    "    minDate=(\"Shamsi_Date_Num\", \"min\"),\n",
    "    maxDate=(\"Shamsi_Date_Num\", \"max\")\n",
    ")\n",
    "\n",
    "# Initialize R_InitDF DataFrame\n",
    "R_InitDF = pd.DataFrame(columns=[\"user_id\", \"R\"])\n",
    "\n",
    "# Calculate R\n",
    "for i in range(len(TrainRFM_RB)):\n",
    "    R_Init = (np.where(MainDates == EndDate)[0][0] - np.where(MainDates == TrainRFM_RB.loc[i, \"maxDate\"])[0][0]) + 1\n",
    "    R_InitDF.loc[i] = [TrainRFM_RB.loc[i, \"user_id\"], R_Init]\n",
    "    print(i)\n",
    "\n",
    "# Merge R values back into TrainRFM_RB\n",
    "TrainRFM_RB = TrainRFM_RB.merge(R_InitDF, on=\"user_id\", how=\"left\")\n"
   ],
   "id": "152f3bcf22fb0a0d",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['Shamsi_Date_Num'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Group by user_id and calculate min and max dates\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m TrainRFM_RB \u001B[38;5;241m=\u001B[39m \u001B[43mTrainRFM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mminDate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mShamsi_Date_Num\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaxDate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mShamsi_Date_Num\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Initialize R_InitDF DataFrame\u001B[39;00m\n\u001B[0;32m      8\u001B[0m R_InitDF \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mR\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001B[0m, in \u001B[0;36mDataFrameGroupBy.aggregate\u001B[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1429\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m engine_kwargs\n\u001B[0;32m   1431\u001B[0m op \u001B[38;5;241m=\u001B[39m GroupByApply(\u001B[38;5;28mself\u001B[39m, func, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m-> 1432\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1433\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dict_like(func) \u001B[38;5;129;01mand\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1434\u001B[0m     \u001B[38;5;66;03m# GH #52849\u001B[39;00m\n\u001B[0;32m   1435\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mas_index \u001B[38;5;129;01mand\u001B[39;00m is_list_like(func):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:190\u001B[0m, in \u001B[0;36mApply.agg\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_dict_like(func):\n\u001B[1;32m--> 190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg_dict_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(func):\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;66;03m# we require a list, but not a 'str'\u001B[39;00m\n\u001B[0;32m    193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magg_list_like()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:423\u001B[0m, in \u001B[0;36mApply.agg_dict_like\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21magg_dict_like\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m    416\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[38;5;124;03m    Result of aggregation.\u001B[39;00m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 423\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg_or_apply_dict_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43magg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1608\u001B[0m, in \u001B[0;36mGroupByApply.agg_or_apply_dict_like\u001B[1;34m(self, op_name)\u001B[0m\n\u001B[0;32m   1603\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine\u001B[39m\u001B[38;5;124m\"\u001B[39m: engine, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: engine_kwargs})\n\u001B[0;32m   1605\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m com\u001B[38;5;241m.\u001B[39mtemp_setattr(\n\u001B[0;32m   1606\u001B[0m     obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas_index\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m, condition\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mhasattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas_index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1607\u001B[0m ):\n\u001B[1;32m-> 1608\u001B[0m     result_index, result_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_dict_like\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1609\u001B[0m \u001B[43m        \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m   1610\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1611\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001B[0;32m   1612\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:462\u001B[0m, in \u001B[0;36mApply.compute_dict_like\u001B[1;34m(self, op_name, selected_obj, selection, kwargs)\u001B[0m\n\u001B[0;32m    460\u001B[0m is_groupby \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001B[0;32m    461\u001B[0m func \u001B[38;5;241m=\u001B[39m cast(AggFuncTypeDict, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc)\n\u001B[1;32m--> 462\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize_dictlike_arg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m is_non_unique_col \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    465\u001B[0m     selected_obj\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    466\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m selected_obj\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnunique() \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(selected_obj\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[0;32m    467\u001B[0m )\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m selected_obj\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    470\u001B[0m     \u001B[38;5;66;03m# key only used for output\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:663\u001B[0m, in \u001B[0;36mApply.normalize_dictlike_arg\u001B[1;34m(self, how, obj, func)\u001B[0m\n\u001B[0;32m    661\u001B[0m     cols \u001B[38;5;241m=\u001B[39m Index(\u001B[38;5;28mlist\u001B[39m(func\u001B[38;5;241m.\u001B[39mkeys()))\u001B[38;5;241m.\u001B[39mdifference(obj\u001B[38;5;241m.\u001B[39mcolumns, sort\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    662\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(cols) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 663\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(cols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m do not exist\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    665\u001B[0m aggregator_types \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mdict\u001B[39m)\n\u001B[0;32m    667\u001B[0m \u001B[38;5;66;03m# if we have a dict of any non-scalars\u001B[39;00m\n\u001B[0;32m    668\u001B[0m \u001B[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001B[39;00m\n\u001B[0;32m    669\u001B[0m \u001B[38;5;66;03m# be list-likes\u001B[39;00m\n\u001B[0;32m    670\u001B[0m \u001B[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001B[39;00m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Column(s) ['Shamsi_Date_Num'] do not exist\""
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "680eed518e31c009"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
